%---------------------------------------------------------------------------
% System tests.
%
%---------------------------------------------------------------------------
\section{System Tests}
\label{sec:tests}
\subsection{Performance tests}

In order to evaluate system performance abilities and to find potential bottlenecks, load tests were performed. Due to lack of resources, setup used for this purpose was rather simple. For test purposes I have used 2 machines: 

\begin{itemize}
\item {\bf HP nx6110} laptop having Pentium M 1.73 GHz CPU and 1.5GB of RAM, running Ubuntu Linux
\item {\bf Sony Vaio VPCEB2Z1E}, with Pentium i5 M430, running at 2.24GHz with 2 physical cores and two processing pipelines running on each core, additionally having 4GB of RAM. This machine was running Microsoft Windows7.
\end{itemize}
Those machines where connected using 100Mb Fast Ethernet switch.
Test scenario was composed of following steps:
\begin{enumerate}
\item Launch Monitoring Hub Application module
\item Launch GUI module
\item On separate machine launch 3 JVM processes that mimic processing workflow
\item Again, on testing machine launch iptraf to have insight to network load
\item Launch 2 JProfiler\footnote{\url{http://www.ej-technologies.com/products/jprofiler/overview.html}} instances, attach them to GUI and Monitoring Hub processes
\item Using GUI module and external Monitoring Hub Application started in previous step, add all 3 JVMs as measured resources
\item Create 20 sample measurements, covering: Memory usage, CPU usage, per process Heap and Non Heap memory usage
\item Create 5 Visualizations, using all types that system supports and measurements created in previous step
\item Let the system running for a while, so it is possible to gather performance data of system being on severe load
\item Dispose visualizations
\item Dispose measurements
\item Remove resources
\item Leave system running for short period of time, to make sure that CPU and memory usage returns to values from idle state
\end{enumerate}

In designed scenario, I am using external Monitoring Hub Application to verify resources usage of each component separately. Additionally, HP laptop was running test application and Vaio was running monitoring system. I have decided to use those resources in that way, to make sure that system being tested will not reach machine limits to be certain that results aren\rq{}t polluted with edge conditions. Results of tests can be found below.


Figure~\ref{fig:prof_GUI} depicts JVM telemetry measurements produced by JProfiler during stage of tests where system where operating under heaviest load (Step~9 from list above). As can be seen, system never consumed more than 90MB of used memory. The maximum of commit memory slightly exceeded 140MB. On the other hand, the CPU time spent on actual data processing never reached 18\%, having an average between 2\% and 8\%. What is quite interesting is the Garbage Collection, most of the time CPU time spent on garbage collection was hardly traceable, but there were 2 peaks where GC consumed nearly 20\% of CPU time. 

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{prof_GUI}
\caption{Profiling results of GUI component}
\label{fig:prof_GUI}
\end{figure}


As it is easily predictable, the Monitoring Hub module was consuming significantly smaller portion of resources then the GUI. Figure~\ref{fig:prof_mon_hub} covers telemetry of Monitoring Hub JVM process in same time frame (step 9 of test scenario). Module\rq{}s CPU usage was only fraction of GUI usage - peak was about 1.6\%. Regarding memory usage - Those values also were smaller than in GUI but significant - memory really used by application was staying in 10-20MB range, commit memory was nearly constant and equal to approximately 50MB.

Additionally network usage rendered by iptraf showed near constant bit rate equal to 130kbps.

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{prof_mon_hub}
\caption{Profiling results of Monitoring Hub component}
\label{fig:prof_mon_hub}
\end{figure}

Test results showed clearly that performance of proposed system is good enough to say that there aren\rq{}t any significant bottlenecks. Additionally, really low resources usage of Monitoring Hub builds solid scaffold for further scaling the application up.

Such a good results could be obtained mostly by keeping code that is responsible for processing measurements really simple and optimized. Measurement processing consists only of gathering data and transmitting them to other layers.


\subsection{Usability tests}

As was previously stated, in the beginning of this chapter, in order to prove that system is really useful, test with real world application were performed. In this subsection, I will cover this test - from stating the problem, describing solution, implemented test application ending up with benefits that SemSimMon gives application author.

Let us assume that we\rq{}ve got an assignment - create an application that will solve linear problems and that will provide basic Web UI for accessing its services. Application should allow user to provide any square linear system using UI and will render result vector in same view. Application should optimize response time rather than high throughput. Additionally, to ensure response time, proposed solution shall operate on MPI-powered cluster and external server machine that is capable of running HTTP server application. Both cluster and HTTP server machine have same NFS share attached. 

Solution to above problem is a system consisting two modules: web application providing interface and processing application that solves the equations and runs on MPI cluster. Web application submits jobs for the cluster using NFS share, by creating request file. Solving module, checks for new jobs by polling for new request file, solves the equation and then generates response file. Web application, after submitting new job file, simply waits for solution by polling same NFS share for result file. 

System was implemented as a J2EE application and standalone, parallel application for solving equations. Sources of both components can be found in test-webapp module along with rest of SemSimMon components.

After implementing above application, one should try to analyze its behavior under some load. Due to same lack of resources, tests were performed on cluster, composed of 2 virtual nodes. Virtual nodes were created using Oracle VirtualBox platform, and both were running 32-bit Ubuntu 9.10. The first, main node was running both HTTP server and main node of equations solving cluster. The second node was just computing one. For measuring load purposes, I have been using SemSimMon running on Guest (Windows 7) OS. 

After attaching to all resources, I have started following metrics:
\begin{itemize}
\item Heap and non-heap memory usage of tomcat server
\item CPU usage of tomcat server
\item System load for both MPI nodes
\end{itemize}

Figures~\ref{fig:http_cpu}and\ref{fig:http_memory} depicts screen shots made from SemSimMon\rq{}s visualizations view. As we can see, memory usage was constant during all the test time. Non heap memory usage (red, labeled as HTTPNH) was between 22MB and 23MB. Heap memory was a bit more dynamic, but was oscillating between 4MB and 8MB. The CPU usage was barely traceable - between 0\% and 5.5\%. The area of plot circled highlights a slightly bigger - this area represents time, when system was under some load. There were several requests performed, which stuck on solver. During this stage web app was polling for resource file. In spite of that, CPU usage was minimal, which was quite predictable. 

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{http_memory}
\caption{Test J2EE web app monitoring - memory}
\label{fig:http_memory}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{http_cpu}
\caption{Test J2EE web app monitoring - CPU}
\label{fig:http_cpu}
\end{figure}


Results of system solver analysis are a bit more interesting. In Figure~\ref{fig:clu1_clu3_asymetry} we can see plot of node avg load in last 1min of 2 nodes in cluster. The red line, labeled as Clu3Load represents load of working node (the one with rank != 0), the blue one, CLu1Load represents master node. We can see clearly that implemented application has huge imbalance - while master node is mostly idle, the slave is running nearly at 99\% of CPU. The part of plot highlighted with ellipse covers time when system were working under some moderate load. As we can see, it\rq{}s load increased a bit, but the working node was constantly using almost every resources available. Figure~\ref{fig:clu1_clu3_asymetry2} contains bar chart of Node Load in last 5 min metrics of both those nodes. While node clu1 stays below 0.1, the clu3 is above 0.9 which highlights the asymmetry even more. Figure~\ref{fig:total_cpu_time} depicts total cpu time of both processes running example solver. Here, process running worker code reached 325 seconds of its processor, while the master was totally idle. The last figure was made before any input was given for the application, which shows that master process waits for input data appropriately.

\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{clu1_clu3_asymetry}
\caption{MPI based linear systems solver: Node Load Average - 1min}
\label{fig:clu1_clu3_asymetry}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{clu1_clu3_asymetry2}
\caption{MPI based linear systems solver: Node Load Average - 5min}
\label{fig:clu1_clu3_asymetry2}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{total_cpu_time}
\caption{MPI based linear systems solver: CPU time}
\label{fig:total_cpu_time}
\end{figure}
